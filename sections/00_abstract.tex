\MakeAbstract{
    大规模场景的传统建图方法存在地图精细度与存储大小无法兼顾的问题, 其在无人驾驶领域的应用同时需要建图算法满足可扩展性,实时性与健壮性。近年来, 基于神经网络的隐式场景表示方法在众多领域展现出令人激动的效果。依赖神经网络的连续性,可以实现以较小的存储代价以任意分辨率对地图进行重建,以及对未观察到的场景进行预测。在无人驾驶相关领域,出现了许多基于这一技术的视觉实时定位与建图方法,其依赖神经网络进行位姿和场景特征的优化和地图的渲染。目前这些方法存在的缺陷有地图不可扩展,存在遗忘问题以及训练时间过长等。

    本文实现了一种基于体素的显式与隐式相结合的实时建图方法,以稀疏点云作为输入,将地图的几何,外观与语义信息存储在体素网格中,使用多个解码器进行提取。其中,本文将几何信息编码为连续的符号距离场函数,使用基于表面的神经网络重建方法进行渲染。进一步,本文使用了基于八叉树的体素管理方法划分场景,可以实现地图的动态扩展和特征信息的快速查找,并且无需场景的先验信息。本文的系统使用多线程进行加速,并且设计了一个关键帧选择策略来克服神经网络的遗忘问题。
    
    除实现上述方法外,本文实现了一系列对地图重建几何精度与语义建图精度进行定性与定量评估的流程,并扩展和使用多种传统视觉定位与建图方法与神经隐式表示方法在合成场景数据集与真实场景数据集上分别进行了对比实验,对结果进行了分析与讨论。实验证明本文可以满足无人驾驶仿真的相关需求。本文的代码公开在\href{https://github.com/tiev-tongji/semantic-neural-lidar-mapping}{https://github.com/tiev-tongji/semantic-neural-lidar-mapping}
}{神经辐射场,实时定位与建图,八叉树,无人驾驶,语义建图}

\MakeAbstractEng{
    The traditional mapping method of large-scale scenes has the problem that the map fineness and storage size cannot be balanced, and its application in the field of autonomous driving requires the algorithm to meet scalability, real-time and robustness. In recent years, implicit scene representation methods based on neural networks have shown encouraging results in many fields. Relying on the continuity of neural networks makes it possible to reconstruct maps at any resolution at a lower storage cost, as well as make predictions of unobserved scenes. In the field of autonomous driving, many visual simultaneous localization and mapping methods based on this algorithm, which rely on neural networks to optimize pose and scene features then render maps. At present, the limitations of these methods include the map is unscalable, catastrophic forgetting problem, and training time is too long etc.

    We implement a real-time voxel-based mapping method combining explicit and implicit. It using sparse point clouds as input, storing the geometric, appearance, and semantic information of the map in a voxel grid and extracting it using multiple decoders. We model the scene geometry within local voxels as a continuous signed distance function, then use neural surface reconstrction method to render. Furthermore, we use a octree-based voxel management method to divide the scene, enabling the dynamic expansion of the map and the rapid search of feature information, and do not need the prior information of the scene. Our system uses multithreading for acceleration, and a keyframe selection strategy is designed to overcome the neural network forgetting problem. 
    
    In addition to implementing the aforementioned methods, we presents a series of qualitative and quantitative evaluations for assessing the geometric accuracy and semantic mapping precision of the map reconstruction. Various traditional visual localization and mapping methods, as well as neural implicit representation methods, are extended and utilized for comparative experiments on synthetic and real-world scene datasets. The results are analyzed and discussed. The results show that our algorithm can meet the requirements of autonomous driving simulation. Our source code is publicly available at \href{https://github.com/tiev-tongji/semantic-neural-lidar-mapping}{https://github.com/tiev-tongji/semantic-neural-lidar-mapping}
}{NeRF, SLAM, octree, autonomous driving, semantic mapping}
